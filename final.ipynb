{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UGbZHK27Hzsv"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ZDmV62z_0hTl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset as TorchDataset\n",
        "from datasets import load_dataset, Dataset, ClassLabel\n",
        "from transformers import (\n",
        "    RobertaTokenizerFast,\n",
        "    RobertaForSequenceClassification,\n",
        "    RobertaForTokenClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "import evaluate\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "zzAVnKnhJtaM"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "\n",
        "dataset_percent = 1 # 0.1 => 10%\n",
        "\n",
        "train_percent = 0.75\n",
        "eval_percent  = 0.10\n",
        "test_percent  = 0.15\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "tokenizer_name        = \"neulab/codebert-cpp\"\n",
        "fn_level_model_name   = \"neulab/codebert-cpp\"\n",
        "line_level_model_name = \"neulab/codebert-cpp\"\n",
        "\n",
        "use_tokenizer_max_length = True # if False: use below\n",
        "tokenizer_max_length     = 2048\n",
        "\n",
        "download_model = True\n",
        "\n",
        "fn_level_trainer_args = TrainingArguments(\n",
        "    output_dir=\"./fn-level\",\n",
        "    learning_rate=2e-5,\n",
        "    eval_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=epochs,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"mcc\",\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "line_level_trainer_args = TrainingArguments(\n",
        "    output_dir=\"./line-level\",\n",
        "    learning_rate=2e-5,\n",
        "    eval_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=epochs,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"mcc\",\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "PdI6tpGKzOhJ"
      },
      "outputs": [],
      "source": [
        "assert train_percent + eval_percent + test_percent == 1\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "collapsed": true,
        "id": "pue27eih1OCL"
      },
      "outputs": [],
      "source": [
        "bugvul_zip_url = \"https://raw.githubusercontent.com/Meerschwein/Automating-SE/refs/heads/main/Big-Vul-dataset.zip\"\n",
        "data_path = \"Big-Vul-dataset/data.json\"\n",
        "\n",
        "if not os.path.exists(\"Big-Vul-dataset.zip\"):\n",
        "    urllib.request.urlretrieve(bugvul_zip_url, \"Big-Vul-dataset.zip\")\n",
        "\n",
        "if not os.path.exists(\"Big-Vul-dataset\"):\n",
        "    with zipfile.ZipFile(\"Big-Vul-dataset.zip\", \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\"Big-Vul-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfRyATmL5bP0",
        "outputId": "7f422c91-15d1-4aef-a9af-67f6738480cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset   75.00% 139706\n",
            "Validation Dataset 10.00% 18627\n",
            "Test Dataset       15.00% 27942\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_json(data_path, dtype={\"vul\": \"int8\"})\n",
        "\n",
        "df = (df.drop([\"bigvul_id\"], axis=1)\n",
        "        .rename(columns={\"vul\": \"labels\"})\n",
        "        .dropna(subset=[\"code\", \"labels\"])\n",
        "        .drop_duplicates(\"code\")\n",
        "        .reset_index(drop=True))\n",
        "\n",
        "if 0 < dataset_percent < 1: # smaller for training\n",
        "    df, _ = train_test_split(df, test_size=1-dataset_percent, stratify=df['labels'], random_state=seed)\n",
        "\n",
        "train_df, eval_test_df = train_test_split(df, train_size=train_percent, stratify=df['labels'], random_state=seed)\n",
        "eval_df, test_df = train_test_split(eval_test_df, test_size=test_percent/(test_percent+eval_percent), stratify=eval_test_df['labels'], random_state=seed)\n",
        "\n",
        "raw_train_ds = Dataset.from_pandas(train_df, preserve_index=False)\n",
        "raw_eval_ds  = Dataset.from_pandas(eval_df, preserve_index=False)\n",
        "raw_test_ds  = Dataset.from_pandas(test_df, preserve_index=False)\n",
        "\n",
        "print(f\"Training Dataset   {((len(raw_train_ds)/len(df))*100):.2f}% {len(raw_train_ds)}\")\n",
        "print(f\"Validation Dataset {((len(raw_eval_ds)/len(df))*100):.2f}% {len(raw_eval_ds)}\")\n",
        "print(f\"Test Dataset       {((len(raw_test_ds)/len(df))*100):.2f}% {len(raw_test_ds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eOK1vNgU6gIr"
      },
      "outputs": [],
      "source": [
        "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_name)\n",
        "fn_level_model = RobertaForSequenceClassification.from_pretrained(fn_level_model_name, num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4SL6CGbTIA7W"
      },
      "outputs": [],
      "source": [
        "def tokenize(batch):\n",
        "    max_length = tokenizer.model_max_length if use_tokenizer_max_length else tokenizer_max_length\n",
        "    return tokenizer(batch[\"code\"], padding=\"max_length\", truncation=True, max_length=max_length)\n",
        "\n",
        "fn_level_train_ds = raw_train_ds.map(tokenize, batched=True, remove_columns=[\"code\"])\n",
        "fn_level_eval_ds  = raw_eval_ds.map(tokenize, batched=True, remove_columns=[\"code\"])\n",
        "fn_level_test_ds  = raw_test_ds.map(tokenize, batched=True, remove_columns=[\"code\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "collapsed": true,
        "id": "kQoUpyPhILFX"
      },
      "outputs": [],
      "source": [
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "precision_metric = evaluate.load(\"precision\")\n",
        "recall_metric = evaluate.load(\"recall\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "mcc_metric = evaluate.load(\"matthews_correlation\")\n",
        "auc_metric = evaluate.load(\"roc_auc\")\n",
        "\n",
        "metrics_include_report = False\n",
        "\n",
        "def fn_level_compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(logits), dim=1)[:, 1].numpy()  # Probability of class 1 (vulnerable)\n",
        "\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    precision = precision_metric.compute(predictions=predictions, references=labels)[\"precision\"]\n",
        "    recall = recall_metric.compute(predictions=predictions, references=labels)[\"recall\"]\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels)[\"f1\"]\n",
        "    mcc = mcc_metric.compute(predictions=predictions, references=labels)[\"matthews_correlation\"]\n",
        "    auc = auc_metric.compute(prediction_scores=probs, references=labels)[\"roc_auc\"]\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"mcc\": mcc,\n",
        "        \"auc\": auc,\n",
        "    }\n",
        "\n",
        "    if metrics_include_report:\n",
        "        report = classification_report(labels, predictions, target_names=[\"Non-vulnerable\", \"Vulnerable\"])\n",
        "        metrics[\"report\"] = report\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def test_model(trainer, test_dataset):\n",
        "    global metrics_include_report\n",
        "    metrics_include_report = True\n",
        "    evaluation_results = trainer.evaluate(test_dataset)\n",
        "    evaluation_df = pd.DataFrame([evaluation_results])\n",
        "    evaluation_df.columns = evaluation_df.columns.str.replace('eval_', '')\n",
        "    evaluation_df = evaluation_df.drop([\"samples_per_second\", \"steps_per_second\", \"epoch\", \"runtime\", \"report\", \"loss\"], axis=1)\n",
        "    display(evaluation_df)\n",
        "    print(evaluation_results[\"eval_report\"])\n",
        "    metrics_include_report = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "3eN-vEYfMrDK",
        "outputId": "ec77ddf5-6f2f-476c-8125-3019107eaf87"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3276' max='3276' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3276/3276 2:43:23, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Mcc</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.059700</td>\n",
              "      <td>0.051294</td>\n",
              "      <td>0.987169</td>\n",
              "      <td>0.958393</td>\n",
              "      <td>0.760820</td>\n",
              "      <td>0.848254</td>\n",
              "      <td>0.847766</td>\n",
              "      <td>0.969998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.048700</td>\n",
              "      <td>0.048854</td>\n",
              "      <td>0.987491</td>\n",
              "      <td>0.961373</td>\n",
              "      <td>0.765376</td>\n",
              "      <td>0.852251</td>\n",
              "      <td>0.851805</td>\n",
              "      <td>0.969701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.038700</td>\n",
              "      <td>0.048408</td>\n",
              "      <td>0.988243</td>\n",
              "      <td>0.957004</td>\n",
              "      <td>0.785877</td>\n",
              "      <td>0.863039</td>\n",
              "      <td>0.861501</td>\n",
              "      <td>0.975610</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fn_level_trainer = Trainer(\n",
        "    args=fn_level_trainer_args,\n",
        "    model=fn_level_model,\n",
        "    train_dataset=fn_level_train_ds,\n",
        "    eval_dataset=fn_level_eval_ds,\n",
        "    processing_class=tokenizer,\n",
        "    compute_metrics=fn_level_compute_metrics,\n",
        ")\n",
        "\n",
        "fn_level_trainer.train()\n",
        "fn_level_trainer.save_model(\"fn-level-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "hb_ocDNSiB4A",
        "outputId": "901c2b5b-e40b-4344-801d-8b36a8c9aa0b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='874' max='874' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [874/874 03:14]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   accuracy  precision    recall        f1       mcc       auc\n",
              "0  0.987904   0.940647  0.793627  0.860905  0.858004  0.976235"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd3b68fc-f5aa-4b99-b148-1ae05749debe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>mcc</th>\n",
              "      <th>auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.987904</td>\n",
              "      <td>0.940647</td>\n",
              "      <td>0.793627</td>\n",
              "      <td>0.860905</td>\n",
              "      <td>0.858004</td>\n",
              "      <td>0.976235</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd3b68fc-f5aa-4b99-b148-1ae05749debe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd3b68fc-f5aa-4b99-b148-1ae05749debe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd3b68fc-f5aa-4b99-b148-1ae05749debe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"test_model(fn_level_trainer, fn_level_test_ds)\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9879035144227328,\n        \"max\": 0.9879035144227328,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9879035144227328\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9406474820143885,\n        \"max\": 0.9406474820143885,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9406474820143885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7936267071320182,\n        \"max\": 0.7936267071320182,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7936267071320182\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8609053497942387,\n        \"max\": 0.8609053497942387,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8609053497942387\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mcc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8580038166427816,\n        \"max\": 0.8580038166427816,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8580038166427816\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9762346328480652,\n        \"max\": 0.9762346328480652,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9762346328480652\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "Non-vulnerable       0.99      1.00      0.99     26624\n",
            "    Vulnerable       0.94      0.79      0.86      1318\n",
            "\n",
            "      accuracy                           0.99     27942\n",
            "     macro avg       0.97      0.90      0.93     27942\n",
            "  weighted avg       0.99      0.99      0.99     27942\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_model(fn_level_trainer, fn_level_test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_model(dir):\n",
        "    files.download(shutil.make_archive(dir, 'zip', dir))"
      ],
      "metadata": {
        "id": "Sx0E-NT3Ay8G"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Jl2-TgflGqA4"
      },
      "outputs": [],
      "source": [
        "if download_model:\n",
        "    download_model(\"./fn-level-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PARle_GS5Vd"
      },
      "outputs": [],
      "source": [
        "def add_token_labels(example):\n",
        "    code        = example[\"code\"]\n",
        "    vuln_lines  = set(example[\"flaw_line_no\"]) # [] if benign\n",
        "\n",
        "    max_length = tokenizer.model_max_length if use_tokenizer_max_length else tokenizer_max_length\n",
        "    enc = tokenizer(\n",
        "        code,\n",
        "        return_offsets_mapping=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # map every token to its source-code line\n",
        "    labels = np.full(len(enc[\"input_ids\"]), -100, dtype=np.int8) # pad value\n",
        "    line_start = [0] + [i + 1 for i, c in enumerate(code) if c == \"\\n\"]\n",
        "\n",
        "    for idx, (start, _) in enumerate(enc[\"offset_mapping\"]):\n",
        "        if start == 0 and idx == 0: # [CLS] token => keep -100\n",
        "            continue\n",
        "        # line numbers are 1-based\n",
        "        line_no = 1 + sum(start >= ls for ls in line_start)\n",
        "        labels[idx] = int(line_no in vuln_lines)\n",
        "\n",
        "    enc.pop(\"offset_mapping\")\n",
        "    enc[\"labels\"] = labels.tolist()\n",
        "    return enc\n",
        "\n",
        "line_level_train_ds = raw_train_ds.map(add_token_labels, remove_columns=list(train_df.columns))\n",
        "line_level_eval_ds  = raw_eval_ds.map(add_token_labels, remove_columns=list(train_df.columns))\n",
        "line_level_test_ds  = raw_test_ds.map(add_token_labels, remove_columns=list(train_df.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-bmlLOVUpuk"
      },
      "outputs": [],
      "source": [
        "metrics_include_report = False\n",
        "def line_level_metrics(eval_pred):\n",
        "    logits, y = eval_pred\n",
        "    logits_flat = logits.reshape(-1, logits.shape[-1]) # Flatten logits for masking\n",
        "    p = logits.argmax(-1).flatten()\n",
        "    y = y.flatten()\n",
        "    mask = y != -100 # ignore padding tokens\n",
        "    predictions, labels = p[mask], y[mask]\n",
        "    logits_masked = logits_flat[mask]\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(logits_masked), dim=1)[:, 1].numpy()  # Probability of class 1 (vulnerable)\n",
        "\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    precision = precision_metric.compute(predictions=predictions, references=labels)[\"precision\"]\n",
        "    recall = recall_metric.compute(predictions=predictions, references=labels)[\"recall\"]\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels)[\"f1\"]\n",
        "    mcc = mcc_metric.compute(predictions=predictions, references=labels)[\"matthews_correlation\"]\n",
        "    auc = auc_metric.compute(prediction_scores=probs, references=labels)[\"roc_auc\"]\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"mcc\": mcc,\n",
        "        \"auc\": auc,\n",
        "    }\n",
        "\n",
        "    if metrics_include_report:\n",
        "        report = classification_report(labels, predictions, target_names=[\"Non-vulnerable\", \"Vulnerable\"])\n",
        "        metrics[\"report\"] = report\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line_level_model = RobertaForTokenClassification.from_pretrained(line_level_model_name, num_labels=2)"
      ],
      "metadata": {
        "id": "wXDl_Z8m9atu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_B26W8qVViF"
      },
      "outputs": [],
      "source": [
        "line_level_trainer = Trainer(\n",
        "    args=line_level_trainer_args,\n",
        "    model=line_level_model,\n",
        "    train_dataset=line_level_train_ds,\n",
        "    eval_dataset=line_level_eval_ds,\n",
        "    processing_class=tokenizer,\n",
        "    compute_metrics=line_level_metrics,\n",
        ")\n",
        "\n",
        "line_level_trainer.train()\n",
        "line_level_trainer.save_model(\"line-level-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-X67vGJWuZF"
      },
      "outputs": [],
      "source": [
        "test_model(line_level_trainer, line_level_test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0fMDVZSWfsM"
      },
      "outputs": [],
      "source": [
        "if download_model:\n",
        "    download_model(\"line-level-model\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith(\".zip\"):\n",
        "        folder_name = filename.replace(\".zip\", \"\")\n",
        "        os.makedirs(folder_name, exist_ok=True)\n",
        "        !unzip -q \"$filename\" -d \"$folder_name\""
      ],
      "metadata": {
        "id": "eF5l8zsmFp-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFUCs2eMGrpP"
      },
      "outputs": [],
      "source": [
        "trained_fn_level_model = RobertaForSequenceClassification.from_pretrained(\"./fn-level-model\")\n",
        "trained_line_level_model = RobertaForTokenClassification.from_pretrained(\"./line-level-model\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "_ = trained_fn_level_model.to(device).eval()\n",
        "_ = trained_line_level_model.to(device).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWohD27Cqf6e"
      },
      "outputs": [],
      "source": [
        "def get_vuln_lines(example):\n",
        "    code = example[\"code\"]\n",
        "\n",
        "    # Function-level classification\n",
        "    fn_inputs = tokenizer(code, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
        "    fn_inputs = {k: v.to(device) for k, v in fn_inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        fn_outputs = trained_fn_level_model(**fn_inputs)\n",
        "        fn_probs = torch.softmax(fn_outputs.logits, dim=1)\n",
        "    is_vulnerable = fn_probs[0][1].item() > 0.5  # Class 1 = vulnerable\n",
        "\n",
        "    if not is_vulnerable:\n",
        "        return {\"vulnerable\": False, \"lines\": []}\n",
        "\n",
        "    # Line-level classification\n",
        "    enc = tokenizer(code, return_offsets_mapping=True, return_tensors=\"pt\",\n",
        "                    truncation=True, padding=\"max_length\", max_length=512)\n",
        "    offset_mapping = enc.pop(\"offset_mapping\")[0]\n",
        "    enc = {k: v.to(device) for k, v in enc.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        line_outputs = trained_line_level_model(**enc)\n",
        "    line_logits = line_outputs.logits\n",
        "    line_preds = torch.argmax(line_logits, dim=-1)[0]  # shape: [seq_len]\n",
        "\n",
        "    # Map tokens to line numbers\n",
        "    lines = code.split('\\n')\n",
        "    line_start_positions = [0]\n",
        "    for line in lines:\n",
        "        line_start_positions.append(line_start_positions[-1] + len(line) + 1)\n",
        "\n",
        "    line_indices = set()\n",
        "    for idx, (start_offset, _) in enumerate(offset_mapping):\n",
        "        if start_offset == 0 and idx == 0:  # [CLS] token\n",
        "            continue\n",
        "        if line_preds[idx].item() == 1:\n",
        "            start = start_offset.item()\n",
        "            line_no = 1 + sum(start >= pos for pos in line_start_positions)\n",
        "            line_indices.add(line_no)\n",
        "\n",
        "    return {\"vulnerable\": True, \"lines\": sorted(line_indices)}\n",
        "\n",
        "def display_vulnerability_result(example, predicted_lines):\n",
        "    code_lines = example[\"code\"].split(\"\\n\")\n",
        "    actual_lines = set(example.get(\"flaw_line_no\", []))\n",
        "    predicted_lines = set(predicted_lines)\n",
        "\n",
        "    max_line_no_width = len(str(len(code_lines)))\n",
        "\n",
        "    print(f\"lines{sorted(actual_lines)} pred{sorted(predicted_lines)}\")\n",
        "    for i, line in enumerate(code_lines, start=1):\n",
        "        line_no = str(i).rjust(max_line_no_width)\n",
        "        actual_flag = \"v\" if i in actual_lines else \" \"\n",
        "        predicted_flag = \"p\" if i in predicted_lines else \" \"\n",
        "        print(f\"{line_no} {actual_flag}{predicted_flag}|{line}\")\n",
        "\n",
        "small_vuln_examples = df[\n",
        "    (df[\"labels\"] == 1) &\n",
        "    (df[\"code\"].apply(lambda c: len(c.splitlines()) <= 10))  # max 7 lines\n",
        "]\n",
        "examples_to_test = small_vuln_examples.sample(n=5, random_state=seed).to_dict(orient=\"records\")\n",
        "\n",
        "for ex in examples_to_test:\n",
        "    result = get_vuln_lines(ex)\n",
        "    print(f\"vuln {ex['labels']==1} pred {result['vulnerable']}\")\n",
        "    display_vulnerability_result(ex, result[\"lines\"])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "keep colab running\n",
        "```js\n",
        "function ClickConnect() {\n",
        "    console.log(\"Working\");\n",
        "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n",
        "}\n",
        "var clicker = setInterval(ClickConnect, 60000);\n",
        "```"
      ],
      "metadata": {
        "id": "xUaOPEz7DYk-"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}